{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import  metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import History\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from pandas import DataFrame\n",
    "import warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "DataImport"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "PATH = os.path.join(\"data\", \"bank-additional\", \"bank-additional\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load_data(filename, path=PATH):\n",
    "    csv_path = os.path.join(path, filename)\n",
    "    return pd.read_csv(csv_path,sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "full_data = load_data(\"bank-additional-full.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "seed=64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cater=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "cater_no_def=['job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "numer=['age', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "all=['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome','age', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed','y']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class DulicateDeleter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        return X.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def unknown_number(row):\n",
    "    bbb=0\n",
    "    # print(row)\n",
    "    for sa in row:\n",
    "        if sa == 'unknown':\n",
    "            bbb=bbb+1\n",
    "    return bbb\n",
    "\n",
    "class UnknownDeleter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        return X.drop(X[X.apply(lambda row:unknown_number(row), axis=1)>=3].index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def null_number(row):\n",
    "    bbb=0\n",
    "    # print(row)\n",
    "    for sa in row:\n",
    "        if pd.isnull(sa):\n",
    "            bbb=bbb+1\n",
    "    return bbb\n",
    "\n",
    "class NullDeleter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        return X.drop(X[X.apply(lambda row:null_number(row), axis=1)>=1].index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X,y=None):\n",
    "        return X[self.attribute_names]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "delete_pip = Pipeline([\n",
    "        (\"delete_null\", NullDeleter()),\n",
    "        (\"delete_unknown\", UnknownDeleter()),\n",
    "        (\"delete_duplicates\", DulicateDeleter())\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       age          job  marital            education  default housing loan  \\\n0       56    housemaid  married             basic.4y       no      no   no   \n1       57     services  married          high.school  unknown      no   no   \n2       37     services  married          high.school       no     yes   no   \n3       40       admin.  married             basic.6y       no      no   no   \n4       56     services  married          high.school       no      no  yes   \n...    ...          ...      ...                  ...      ...     ...  ...   \n41183   73      retired  married  professional.course       no     yes   no   \n41184   46  blue-collar  married  professional.course       no      no   no   \n41185   56      retired  married    university.degree       no     yes   no   \n41186   44   technician  married  professional.course       no      no   no   \n41187   74      retired  married  professional.course       no     yes   no   \n\n         contact month day_of_week  ...  campaign  pdays  previous  \\\n0      telephone   may         mon  ...         1    999         0   \n1      telephone   may         mon  ...         1    999         0   \n2      telephone   may         mon  ...         1    999         0   \n3      telephone   may         mon  ...         1    999         0   \n4      telephone   may         mon  ...         1    999         0   \n...          ...   ...         ...  ...       ...    ...       ...   \n41183   cellular   nov         fri  ...         1    999         0   \n41184   cellular   nov         fri  ...         1    999         0   \n41185   cellular   nov         fri  ...         2    999         0   \n41186   cellular   nov         fri  ...         1    999         0   \n41187   cellular   nov         fri  ...         3    999         1   \n\n          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n0      nonexistent          1.1          93.994          -36.4      4.857   \n1      nonexistent          1.1          93.994          -36.4      4.857   \n2      nonexistent          1.1          93.994          -36.4      4.857   \n3      nonexistent          1.1          93.994          -36.4      4.857   \n4      nonexistent          1.1          93.994          -36.4      4.857   \n...            ...          ...             ...            ...        ...   \n41183  nonexistent         -1.1          94.767          -50.8      1.028   \n41184  nonexistent         -1.1          94.767          -50.8      1.028   \n41185  nonexistent         -1.1          94.767          -50.8      1.028   \n41186  nonexistent         -1.1          94.767          -50.8      1.028   \n41187      failure         -1.1          94.767          -50.8      1.028   \n\n       nr.employed    y  \n0           5191.0   no  \n1           5191.0   no  \n2           5191.0   no  \n3           5191.0   no  \n4           5191.0   no  \n...            ...  ...  \n41183       4963.6  yes  \n41184       4963.6   no  \n41185       4963.6   no  \n41186       4963.6  yes  \n41187       4963.6   no  \n\n[40848 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>56</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>basic.4y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>57</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>unknown</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>basic.6y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>services</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.857</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41183</th>\n      <td>73</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>41184</th>\n      <td>46</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>41185</th>\n      <td>56</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>university.degree</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>41186</th>\n      <td>44</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>yes</td>\n    </tr>\n    <tr>\n      <th>41187</th>\n      <td>74</td>\n      <td>retired</td>\n      <td>married</td>\n      <td>professional.course</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>nov</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>3</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.1</td>\n      <td>94.767</td>\n      <td>-50.8</td>\n      <td>1.028</td>\n      <td>4963.6</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>40848 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_pip.fit_transform(full_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n",
      "(40848, 21)\n"
     ]
    }
   ],
   "source": [
    "print(full_data.shape)\n",
    "full_data=delete_pip.fit_transform(full_data)\n",
    "print(full_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "full_data['y'] = label_encoder.fit_transform(full_data['y'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (32678, 20) y_train.shape: (32678,)\n",
      "X_test.shape: (8170, 20) y_test.shape: (8170,)\n"
     ]
    }
   ],
   "source": [
    "full_data=delete_pip.fit_transform(full_data)\n",
    "\n",
    "# _, cut_data = train_test_split(full_data, test_size=0.05, stratify=full_data['y'], random_state=seed)\n",
    "cut_data=full_data\n",
    "\n",
    "X = cut_data.drop(['y'], axis=1)\n",
    "y = cut_data['y'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)\n",
    "print(\"X_train.shape: {} y_train.shape: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"X_test.shape: {} y_test.shape: {}\".format(X_test.shape, y_test.shape))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "pipeline definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "num_pip = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector(numer)),\n",
    "        (\"imputer_mean\", SimpleImputer(missing_values=np.nan, strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.57489342,  0.1968458 , -0.35102053, ...,  0.94680367,\n         0.77827069,  0.84700494],\n       [ 0.86646422,  0.1968458 , -0.35102053, ..., -0.4749137 ,\n         0.77366624,  0.84700494],\n       [ 0.09774014, -5.05872991,  1.66420239, ..., -1.22885473,\n        -1.36337761, -0.93000812],\n       ...,\n       [-0.47880291,  0.1968458 , -0.35102053, ...,  0.94680367,\n         0.77827069,  0.84700494],\n       [-0.95925546,  0.1968458 , -0.35102053, ...,  0.94680367,\n         0.77711958,  0.84700494],\n       [ 2.69218391,  0.1968458 ,  1.66420239, ...,  0.10669795,\n        -1.68108518, -2.17529479]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pip.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "cat_pip = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector(cater_no_def)),\n",
    "        (\"imputer_freq_unk\", SimpleImputer(missing_values=\"unknown\", strategy=\"most_frequent\")),\n",
    "        (\"imputer_freq_nan\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore'))\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       ...,\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 1., 0., 0.]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pip.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "default_pip = Pipeline([\n",
    "        (\"select_default\", DataFrameSelector(['default'])),\n",
    "        (\"imputer_freq\", SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore'))\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.],\n       ...,\n       [1., 0., 0.],\n       [1., 0., 0.],\n       [1., 0., 0.]])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_pip.fit_transform(X_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pip\", num_pip),\n",
    "        (\"cat_pip\", cat_pip),\n",
    "        (\"def_pip\", default_pip)\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6   \\\n0     -0.574893  0.196846 -0.351021  0.842819 -0.223032  0.946804  0.778271   \n1      0.866464  0.196846 -0.351021  0.842819  0.596012 -0.474914  0.773666   \n2      0.097740 -5.058730  1.664202 -1.191444 -1.175127 -1.228855 -1.363378   \n3     -0.670984  0.196846 -0.351021 -1.191444 -1.175127 -1.228855 -1.331722   \n4      0.962555  0.196846 -0.351021 -1.191444 -0.860642 -1.422725 -1.267835   \n...         ...       ...       ...       ...       ...       ...       ...   \n32673 -0.863165  0.196846 -0.351021 -0.746449  2.063034 -2.219749 -1.476187   \n32674 -1.343618  0.196846 -0.351021 -1.890722 -1.054171 -0.065631 -1.353018   \n32675 -0.478803  0.196846 -0.351021  0.842819 -0.223032  0.946804  0.778271   \n32676 -0.959255  0.196846 -0.351021  0.842819 -0.223032  0.946804  0.777120   \n32677  2.692184  0.196846  1.664202 -1.191444  0.523438  0.106698 -1.681085   \n\n             7    8    9   ...   46   47   48   49   50   51   52   53   54  \\\n0      0.847005  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n1      0.847005  0.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0   \n2     -0.930008  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0   \n3     -0.930008  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n4     -0.930008  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n32673 -2.796561  1.0  0.0  ...  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0   \n32674 -1.245462  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0   \n32675  0.847005  0.0  0.0  ...  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0   \n32676  0.847005  0.0  0.0  ...  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0   \n32677 -2.175295  0.0  0.0  ...  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0   \n\n        55  \n0      0.0  \n1      0.0  \n2      0.0  \n3      0.0  \n4      0.0  \n...    ...  \n32673  0.0  \n32674  0.0  \n32675  0.0  \n32676  0.0  \n32677  0.0  \n\n[32678 rows x 56 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.574893</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>0.842819</td>\n      <td>-0.223032</td>\n      <td>0.946804</td>\n      <td>0.778271</td>\n      <td>0.847005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.866464</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>0.842819</td>\n      <td>0.596012</td>\n      <td>-0.474914</td>\n      <td>0.773666</td>\n      <td>0.847005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.097740</td>\n      <td>-5.058730</td>\n      <td>1.664202</td>\n      <td>-1.191444</td>\n      <td>-1.175127</td>\n      <td>-1.228855</td>\n      <td>-1.363378</td>\n      <td>-0.930008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.670984</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>-1.191444</td>\n      <td>-1.175127</td>\n      <td>-1.228855</td>\n      <td>-1.331722</td>\n      <td>-0.930008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.962555</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>-1.191444</td>\n      <td>-0.860642</td>\n      <td>-1.422725</td>\n      <td>-1.267835</td>\n      <td>-0.930008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32673</th>\n      <td>-0.863165</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>-0.746449</td>\n      <td>2.063034</td>\n      <td>-2.219749</td>\n      <td>-1.476187</td>\n      <td>-2.796561</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32674</th>\n      <td>-1.343618</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>-1.890722</td>\n      <td>-1.054171</td>\n      <td>-0.065631</td>\n      <td>-1.353018</td>\n      <td>-1.245462</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32675</th>\n      <td>-0.478803</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>0.842819</td>\n      <td>-0.223032</td>\n      <td>0.946804</td>\n      <td>0.778271</td>\n      <td>0.847005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32676</th>\n      <td>-0.959255</td>\n      <td>0.196846</td>\n      <td>-0.351021</td>\n      <td>0.842819</td>\n      <td>-0.223032</td>\n      <td>0.946804</td>\n      <td>0.777120</td>\n      <td>0.847005</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32677</th>\n      <td>2.692184</td>\n      <td>0.196846</td>\n      <td>1.664202</td>\n      <td>-1.191444</td>\n      <td>0.523438</td>\n      <td>0.106698</td>\n      <td>-1.681085</td>\n      <td>-2.175295</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>32678 rows × 56 columns</p>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(preprocess_pipeline.fit_transform(X_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model learing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "labels = {'model_name': [], 'model': [], 'model_history': [], 'model_params': [], 'proba': [], 'precision_score': [], 'recall_score': [], 'f1_score': [], 'accuracy_score': [], 'balanced_accuracy_score': []}\n",
    "\n",
    "my_models = pd.DataFrame(labels)\n",
    "added_models=0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.5640945969273261, 1: 4.400484783194183}\n",
      "7.800969566388366\n"
     ]
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)\n",
    "class_weights_ratio=class_weights_dict[1]/class_weights_dict[0]\n",
    "print(class_weights_ratio)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def archive_model(name, model, params=None, history=None, proba=False):\n",
    "    y_test_pred=model.predict(X_test)\n",
    "    to_append = {\n",
    "        'model_name': name,\n",
    "        'model': model,\n",
    "        'model_history': history,\n",
    "        'model_params': params,\n",
    "        'proba': proba,\n",
    "        'precision_score': metrics.precision_score(y_test, y_test_pred),\n",
    "        'recall_score': metrics.recall_score(y_test, y_test_pred),\n",
    "        'f1_score': metrics.f1_score(y_test, y_test_pred),\n",
    "        'accuracy_score': metrics.accuracy_score(y_test, y_test_pred),\n",
    "        'balanced_accuracy_score': metrics.balanced_accuracy_score(y_test, y_test_pred)}\n",
    "    return to_append"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DumbClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return np.zeros((len(X)))\n",
    "\n",
    "    def predict_proba(self, X, y=None):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', DumbClassifier())])\n",
    "\n",
    "param_grid = {}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: Dumb Classifier - {}\".format(added_models, None)\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "    archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wojte\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]{'classifier__C': 1, 'classifier__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', LogisticRegression(class_weight=None, solver='liblinear' , verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: Logistic Regression - {}\".format(added_models, None)\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "    archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]{'classifier__C': 0.1, 'classifier__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', LogisticRegression(class_weight='balanced', solver='liblinear' , verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: Logistic Regression - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "    archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', SVC(kernel=\"rbf\", class_weight=None, probability=False, verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__gamma': [10**(-4),10**(-3), 10**(-2), 10**(-1), 1, 10,100],\n",
    "            'classifier__C': [ 10**(-2), 10**(-1), 1, 10**(1), 10**(2)]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: SVC rbf - {}\".format(added_models, None)\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=False, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', SVC(kernel=\"rbf\", class_weight='balanced', probability=False, verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__gamma': [10**(-4),10**(-3), 10**(-2), 10**(-1), 1,],\n",
    "            'classifier__C': [10**(-1), 1, 10**(1), 10**(2), 10**(3)]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n",
    "model_name=\"{}: SVC rbf - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=False, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', SVC(kernel='linear', class_weight='balanced', probability=False, verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [10**(-2), 10**(-1), 1, 10**(1), 10**(2)]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n",
    "model_name=\"{}: SVC linear - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=False ,params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', SVC(kernel='poly', class_weight='balanced', probability=False, verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__degree': [1,2,3,4],\n",
    "            'classifier__C': [10**(-2), 10**(-1), 1, 10**(1), 10**(2)],\n",
    "            'classifier__coef0': [0, 0.5, 1, 2]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: SVC poly - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=False, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', GradientBoostingClassifier( verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "    # \"classifier__loss\":[\"deviance\"],\n",
    "    # \"classifier__learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    # \"classifier__min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    # \"classifier__min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    # \"classifier__max_depth\":[3,5,8],\n",
    "    # \"classifier__max_features\":[\"log2\",\"sqrt\"],\n",
    "    # \"classifier__criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    # \"classifier__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    # \"classifier__n_estimators\":[10]\n",
    "    \"classifier__loss\":[\"deviance\", \"exponential\"],\n",
    "    \"classifier__learning_rate\": [0.01, 0.1, 1],\n",
    "    \"classifier__min_samples_leaf\": [0.1, 0.5],\n",
    "    \"classifier__max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"classifier__criterion\": [\"friedman_mse\",  \"squared_error\"],\n",
    "    \"classifier__subsample\":[ 0.5, 0.8, 1],\n",
    "    \"classifier__n_estimators\":[1, 5, 10]\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: Gradient Boosting - {}\".format(added_models, None)\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', XGBClassifier(scale_pos_weight = class_weights_ratio, verbosity = 2, learning_rate=0.02, n_estimators=600, objective='binary:logistic', nthread=1))])\n",
    "\n",
    "param_grid = {\n",
    "        # 'classifier__min_child_weight': [1, 5, 10],\n",
    "        # 'classifier__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        # 'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "        # 'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        # 'classifier__max_depth': [3, 4, 5]\n",
    "        'classifier__gamma': [0, 0.5, 1, 5],\n",
    "        'classifier__subsample': [0.5, 0.8, 1.0],\n",
    "        'classifier__colsample_bytree': [0.5, 0.8, 1.0],\n",
    "        'classifier__max_depth': [4, 6, 8]\n",
    "        }\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: XGBoost - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', DecisionTreeClassifier(class_weight='balanced', verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "    # 'classifier__max_leaf_nodes': list(range(2, 100)),\n",
    "    # 'classifier__min_samples_split': [2, 3, 4]\n",
    "    'classifier__max_leaf_nodes': [None, 10, 50],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__min_samples_split': [ 2, 3, 4, 5],\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: Decision Tree - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]# Create the random grid\n",
    "# random_grid = {'classifier__n_estimators': [100,250,500,1000],\n",
    "#                'classifier__max_features': ['auto', 'sqrt'],\n",
    "#                'classifier__max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "#                'classifier__min_samples_split': [2, 5, 10],\n",
    "#                'classifier__min_samples_leaf': [1, 2, 4],\n",
    "#                'classifier__bootstrap': [True, False],\n",
    "#                'classifier__criterion': ['gini', 'entropy', 'log_loss'],}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', RandomForestClassifier(class_weight='balanced',verbose=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__max_depth': [ 10, 50, 100],\n",
    "            'classifier__max_features': ['sqrt', 'log2'],\n",
    "            'classifier__bootstrap': [True, False],\n",
    "            'classifier__n_estimators': [100, 250, 500, 1000],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv = kfold, n_jobs = 2, verbose=1, scoring='balanced_accuracy')\n",
    "# grid = RandomizedSearchCV(pipe, random_grid, n_iter = 100, cv = kfold, verbose=2, random_state=seed, n_jobs = 2)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: Random Forest - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "deep shit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape=preprocess_pipeline.transform(X_train).shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neural_network_1():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_dim=input_shape, activation='sigmoid'))\n",
    "    model.add(Dense(16, activation='sigmoid'))\n",
    "    model.add(Dense(8, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(neural_network_1, epochs=100, batch_size=64, validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "trained_model = pipe.fit(X_train, y_train, classifier__callbacks=[history])\n",
    "\n",
    "model_name=\"{}: NN 1 - {}\".format(added_models, None)\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,trained_model, proba=True, history=history), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neural_network_1():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_dim=input_shape, activation='sigmoid'))\n",
    "    model.add(Dense(16, activation='sigmoid'))\n",
    "    model.add(Dense(8, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(neural_network_1, epochs=100, batch_size=64, validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "trained_model = pipe.fit(X_train, y_train, classifier__class_weight=class_weights_dict, classifier__callbacks=[history])\n",
    "\n",
    "model_name=\"{}: NN 1 - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,trained_model, proba=True, history=history), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neural_network_2():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(500, input_dim=input_shape, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(neural_network_2, epochs=100, batch_size=64,  validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "trained_model = pipe.fit(X_train, y_train, classifier__class_weight=class_weights_dict, classifier__callbacks=[history])\n",
    "\n",
    "model_name=\"{}: NN 2 - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,trained_model, proba=True, history=history), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neural_network_3():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Flatten(input_shape=[input_shape]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1000))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(500))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(200))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(neural_network_3, epochs=1000, batch_size=32,  validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "\n",
    "history = History()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, mode='min', verbose=1)\n",
    "trained_model = pipe.fit(X_train, y_train, classifier__class_weight=class_weights_dict, classifier__callbacks=[history,early_stopping])\n",
    "\n",
    "model_name=\"{}: NN 3 - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,trained_model, proba=True, history=history), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model_SGD(lyrs=[16,8], activation='relu', dropout_rate=0.3, lr=0.01, mom=0.0, nest=False):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=[input_shape]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(0,len(lyrs)):\n",
    "        model.add(Dense(lyrs[i]))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=lr, momentum=mom, nesterov=nest)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(build_model_SGD, epochs=100, batch_size=32,  validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "param_distribs = {\n",
    "    \"classifier__lyrs\": [[16,8], [64,32,16], [200,100,50]],\n",
    "    \"classifier__activation\": ['relu', 'elu', 'sigmoid', 'tanh'],\n",
    "    \"classifier__lr\": [0.001, 0.01, 0.1],\n",
    "    \"classifier__dropout_rate\": [0.2, 0.3, 0.4],\n",
    "    \"classifier__mom\": [0.0, 0.5, 0.9],\n",
    "    \"classifier__nest\": [True, False],\n",
    "    \"classifier__batch_size\": [16, 32, 64]\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, mode='min', verbose=1)\n",
    "grid = RandomizedSearchCV(pipe, param_distribs, n_iter=50, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train, classifier__callbacks=[early_stopping])\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: NN SGD RS - {}\".format(added_models, None)\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model_SGD(lyrs=[16,8], activation='relu', dropout_rate=0.3, lr=0.01, mom=0.0, nest=False):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=[input_shape]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(0,len(lyrs)):\n",
    "        model.add(Dense(lyrs[i]))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=lr, momentum=mom, nesterov=nest)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(build_model_SGD, epochs=100, batch_size=32,  validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "param_distribs = {\n",
    "    \"classifier__lyrs\": [[16,8], [64,32,16], [200,100,50]],\n",
    "    \"classifier__activation\": ['relu', 'elu', 'sigmoid', 'tanh'],\n",
    "    \"classifier__lr\": [0.001, 0.01, 0.1],\n",
    "    \"classifier__dropout_rate\": [0.2, 0.3, 0.4],\n",
    "    \"classifier__mom\": [0.0, 0.5, 0.9],\n",
    "    \"classifier__nest\": [True, False],\n",
    "    \"classifier__batch_size\": [16, 32, 64]\n",
    "}\n",
    "#     \"classifier__optimizer\": ['Adam', 'SGD', 'Adagrad']\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, mode='min', verbose=1)\n",
    "grid = RandomizedSearchCV(pipe, param_distribs, n_iter=50, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train,classifier__class_weight=class_weights_dict, classifier__callbacks=[early_stopping])\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: NN SGD RS - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model_Adam(lyrs=[16,8], activation='relu', dropout_rate=0.3, lr=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=[input_shape]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(0,len(lyrs)):\n",
    "        model.add(Dense(lyrs[i]))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(build_model_Adam, epochs=100, batch_size=32,  validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "param_distribs = {\n",
    "    \"classifier__lyrs\": [[16,8], [64,32,16], [200,100,50]],\n",
    "    \"classifier__activation\": ['relu', 'sigmoid', 'tanh'],\n",
    "    \"classifier__lr\": [0.001, 0.01, 0.1],\n",
    "    \"classifier__dropout_rate\": [0.2, 0.3, 0.4],\n",
    "    \"classifier__batch_size\": [16, 32, 64]\n",
    "}\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, mode='min', verbose=1)\n",
    "grid = RandomizedSearchCV(pipe, param_distribs, n_iter=50, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train,classifier__class_weight=class_weights_dict, classifier__callbacks=[early_stopping])\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: NN Adam RS - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model_Adagrad(lyrs=[16,8], activation='relu', dropout_rate=0.3, lr=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=[input_shape]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(0,len(lyrs)):\n",
    "        model.add(Dense(lyrs[i]))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.Adagrad(learning_rate=lr)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = keras.wrappers.scikit_learn.KerasClassifier(build_model_Adagrad, epochs=100, batch_size=32,  validation_split=0.2)\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', model)])\n",
    "history = History()\n",
    "\n",
    "param_distribs = {\n",
    "    \"classifier__lyrs\": [[16,8], [64,32,16], [200,100,50]],\n",
    "    \"classifier__activation\": ['relu', 'sigmoid', 'tanh'],\n",
    "    \"classifier__lr\": [0.001, 0.01, 0.1],\n",
    "    \"classifier__dropout_rate\": [0.2, 0.3, 0.4],\n",
    "    \"classifier__batch_size\": [16, 32, 64]\n",
    "}\n",
    "#     \"classifier__optimizer\": ['Adam', 'SGD', 'Adagrad']\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=40, mode='min', verbose=1)\n",
    "grid = RandomizedSearchCV(pipe, param_distribs, n_iter=50, cv=kfold, verbose=1, scoring='balanced_accuracy')\n",
    "grid.fit(X_train, y_train,classifier__class_weight=class_weights_dict, classifier__callbacks=[early_stopping])\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "model_name=\"{}: NN Adagrad RS - {}\".format(added_models, 'balanced')\n",
    "added_models=added_models+1\n",
    "my_models = my_models.append(\n",
    "archive_model(model_name,grid.best_estimator_, proba=True, params=grid.best_params_), ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_con_mat(name, model):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    cf_matrix_1=metrics.confusion_matrix(y_test, y_test_pred, normalize='true')\n",
    "    cf_matrix_2=metrics.confusion_matrix(y_test, y_test_pred, normalize=None)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,4))\n",
    "\n",
    "    sns.heatmap(cf_matrix_1, annot=True, cmap='Blues', ax=ax1)\n",
    "    sns.heatmap(cf_matrix_2, annot=True, cmap='Blues', ax=ax2)\n",
    "    # Normalized Confusion Matrix\n",
    "    ax1.set_title('{}\\n'.format(name))\n",
    "    ax1.set_xlabel('\\nPredicted Values')\n",
    "    ax1.set_ylabel('Actual Values ')\n",
    "    # Confusion Matrix\n",
    "    ax2.set_title('{}\\n'.format(name))\n",
    "    ax2.set_xlabel('\\nPredicted Values')\n",
    "    ax2.set_ylabel('Actual Values ')\n",
    "\n",
    "    ax1.xaxis.set_ticklabels(['False', 'True'])\n",
    "    ax1.yaxis.set_ticklabels(['False', 'True'])\n",
    "\n",
    "    ax2.xaxis.set_ticklabels(['False', 'True'])\n",
    "    ax2.yaxis.set_ticklabels(['False', 'True'])\n",
    "\n",
    "def show_curves(name, model, proba=False):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    if proba:\n",
    "        y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_test_pred_proba = model.predict(X_test)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,4))\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_test_pred_proba)\n",
    "    # Roc Curve\n",
    "    ax1.plot(fpr, tpr)\n",
    "    ax1.set_title('{}\\n'.format(name))\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_test_pred_proba)\n",
    "\n",
    "    ax2.plot(recall, precision, color='purple')\n",
    "    # Precision-Recall Curve\n",
    "    ax2.set_title('{}\\n'.format(name))\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_xlabel('Recall')\n",
    "\n",
    "def show_history(name, history):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.title('History for {}\\n\\n'.format(name))\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "def plot_bars(df,parametr):\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    print(parametr)\n",
    "\n",
    "    height = df[parametr]\n",
    "    bars = df['model_name']\n",
    "    y_pos = np.arange(len(bars))\n",
    "\n",
    "    plt.bar(y_pos, height)\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "    plt.xticks(y_pos, bars, rotation=90)\n",
    "    plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "    plt.show()\n",
    "def make_bars_2(df):\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (30,10)\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    labels = df['model_name']\n",
    "\n",
    "    bars1 = df['precision_score']\n",
    "    bars2 = df['recall_score']\n",
    "    bars3 = df['f1_score']\n",
    "    bars4 = df['accuracy_score']\n",
    "    bars5 = df['balanced_accuracy_score']\n",
    "\n",
    "    width = 0.15\n",
    "    x = np.arange(len(labels))\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width*2, bars1, width, label='precision_score')\n",
    "    rects2 = ax.bar(x - width*1, bars2, width, label='recall_score')\n",
    "    rects3 = ax.bar(x, bars3, width, label='f1_score')\n",
    "    rects4 = ax.bar(x + width*1, bars4, width, label='accuracy_score')\n",
    "    rects5 = ax.bar(x + width*2, bars5, width, label='balanced_accuracy_score')\n",
    "\n",
    "    ax.set_title('Models parameter breakdown')\n",
    "    ax.set_xticks(x, labels, rotation=90)\n",
    "    ax.legend()\n",
    "\n",
    "    # ax.bar_label(rects1, padding=3)\n",
    "    # ax.bar_label(rects2, padding=3)\n",
    "    # ax.bar_label(rects3, padding=3)\n",
    "    # ax.bar_label(rects4, padding=3)\n",
    "    # ax.bar_label(rects5, padding=3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "yh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_models.drop(['model','model_params', 'model_history', 'proba'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "make_bars_2(my_models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_bars(my_models,'precision_score')\n",
    "plot_bars(my_models,'recall_score')\n",
    "plot_bars(my_models,'f1_score')\n",
    "plot_bars(my_models,'accuracy_score')\n",
    "plot_bars(my_models,'balanced_accuracy_score')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, row in my_models.iterrows():\n",
    "    show_con_mat(row['model_name'], row['model'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, row in my_models.iterrows():\n",
    "    show_curves(row['model_name'], row['model'], row['proba'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for index, row in my_models.iterrows():\n",
    "    if row['model_history'] is not None:\n",
    "        show_history(row['model_name'], row['model_history'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}